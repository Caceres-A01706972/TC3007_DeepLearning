{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir='emotions/train/'\n",
    "validation_data_dir='emotions/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of train_data_dir:\n",
      "angry\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "neutral\n",
      "sad\n",
      "surprise\n",
      "\n",
      "Contents of validation_data_dir:\n",
      "angry\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "neutral\n",
      "sad\n",
      "surprise\n"
     ]
    }
   ],
   "source": [
    "# List all files and subdirectories in the train_data_dir\n",
    "print(\"Contents of train_data_dir:\")\n",
    "for file_or_dir in os.listdir(train_data_dir):\n",
    "    print(file_or_dir)\n",
    "\n",
    "# List all files and subdirectories in the validation_data_dir\n",
    "print(\"\\nContents of validation_data_dir:\")\n",
    "for file_or_dir in os.listdir(validation_data_dir):\n",
    "    print(file_or_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\t\t\t\t\trescale=1./255,\n",
    "\t\t\t\t\trotation_range=30,\n",
    "\t\t\t\t\tshear_range=0.3,\n",
    "\t\t\t\t\tzoom_range=0.3,\n",
    "\t\t\t\t\thorizontal_flip=True,\n",
    "\t\t\t\t\tfill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\t\t\t\t\ttrain_data_dir,\n",
    "\t\t\t\t\tcolor_mode='grayscale',\n",
    "\t\t\t\t\ttarget_size=(48, 48),\n",
    "\t\t\t\t\tbatch_size=32,\n",
    "\t\t\t\t\tclass_mode='categorical',\n",
    "\t\t\t\t\tshuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\t\t\t\t\t\t\tvalidation_data_dir,\n",
    "\t\t\t\t\t\t\tcolor_mode='grayscale',\n",
    "\t\t\t\t\t\t\ttarget_size=(48, 48),\n",
    "\t\t\t\t\t\t\tbatch_size=32,\n",
    "\t\t\t\t\t\t\tclass_mode='categorical',\n",
    "\t\t\t\t\t\t\tshuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels=['Angry','Disgust', 'Fear', 'Happy','Neutral','Sad','Surprise']\n",
    "\n",
    "img, label = train_generator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 22, 22, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2489095 (9.50 MB)\n",
      "Trainable params: 2489095 (9.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n",
      "7178\n"
     ]
    }
   ],
   "source": [
    "train_path = \"emotions/train/\"\n",
    "test_path = \"emotions/test\"\n",
    "\n",
    "num_train_imgs = 0\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "    num_train_imgs += len(files)\n",
    "    \n",
    "num_test_imgs = 0\n",
    "for root, dirs, files in os.walk(test_path):\n",
    "    num_test_imgs += len(files)\n",
    "\n",
    "print(num_train_imgs)\n",
    "print(num_test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "897/897 [==============================] - 550s 612ms/step - loss: 1.7692 - accuracy: 0.2684 - val_loss: 1.6723 - val_accuracy: 0.3337\n",
      "Epoch 2/100\n",
      "897/897 [==============================] - 295s 329ms/step - loss: 1.6449 - accuracy: 0.3431 - val_loss: 1.4582 - val_accuracy: 0.4304\n",
      "Epoch 3/100\n",
      "897/897 [==============================] - 174s 194ms/step - loss: 1.5115 - accuracy: 0.4121 - val_loss: 1.3361 - val_accuracy: 0.4908\n",
      "Epoch 4/100\n",
      "897/897 [==============================] - 164s 183ms/step - loss: 1.4178 - accuracy: 0.4526 - val_loss: 1.2475 - val_accuracy: 0.5183\n",
      "Epoch 5/100\n",
      "897/897 [==============================] - 156s 174ms/step - loss: 1.3575 - accuracy: 0.4800 - val_loss: 1.2407 - val_accuracy: 0.5283\n",
      "Epoch 6/100\n",
      "897/897 [==============================] - 164s 183ms/step - loss: 1.3206 - accuracy: 0.4937 - val_loss: 1.1930 - val_accuracy: 0.5420\n",
      "Epoch 7/100\n",
      "897/897 [==============================] - 168s 188ms/step - loss: 1.2910 - accuracy: 0.5068 - val_loss: 1.1637 - val_accuracy: 0.5555\n",
      "Epoch 8/100\n",
      "897/897 [==============================] - 170s 189ms/step - loss: 1.2649 - accuracy: 0.5167 - val_loss: 1.1625 - val_accuracy: 0.5516\n",
      "Epoch 9/100\n",
      "897/897 [==============================] - 248s 277ms/step - loss: 1.2474 - accuracy: 0.5246 - val_loss: 1.1354 - val_accuracy: 0.5652\n",
      "Epoch 10/100\n",
      "897/897 [==============================] - 306s 341ms/step - loss: 1.2343 - accuracy: 0.5301 - val_loss: 1.1498 - val_accuracy: 0.5615\n",
      "Epoch 11/100\n",
      "897/897 [==============================] - 300s 334ms/step - loss: 1.2254 - accuracy: 0.5332 - val_loss: 1.1247 - val_accuracy: 0.5735\n",
      "Epoch 12/100\n",
      "897/897 [==============================] - 299s 333ms/step - loss: 1.2106 - accuracy: 0.5399 - val_loss: 1.1367 - val_accuracy: 0.5658\n",
      "Epoch 13/100\n",
      "897/897 [==============================] - 273s 304ms/step - loss: 1.2081 - accuracy: 0.5400 - val_loss: 1.0929 - val_accuracy: 0.5809\n",
      "Epoch 14/100\n",
      "897/897 [==============================] - 140s 156ms/step - loss: 1.1917 - accuracy: 0.5462 - val_loss: 1.1242 - val_accuracy: 0.5741\n",
      "Epoch 15/100\n",
      "897/897 [==============================] - 137s 153ms/step - loss: 1.1892 - accuracy: 0.5494 - val_loss: 1.1019 - val_accuracy: 0.5829\n",
      "Epoch 16/100\n",
      "897/897 [==============================] - 139s 155ms/step - loss: 1.1752 - accuracy: 0.5521 - val_loss: 1.1114 - val_accuracy: 0.5816\n",
      "Epoch 17/100\n",
      "897/897 [==============================] - 138s 154ms/step - loss: 1.1723 - accuracy: 0.5557 - val_loss: 1.0652 - val_accuracy: 0.5914\n",
      "Epoch 18/100\n",
      "897/897 [==============================] - 164s 182ms/step - loss: 1.1642 - accuracy: 0.5594 - val_loss: 1.0743 - val_accuracy: 0.5921\n",
      "Epoch 19/100\n",
      "897/897 [==============================] - 376s 420ms/step - loss: 1.1534 - accuracy: 0.5621 - val_loss: 1.0759 - val_accuracy: 0.5938\n",
      "Epoch 20/100\n",
      "897/897 [==============================] - 291s 324ms/step - loss: 1.1443 - accuracy: 0.5630 - val_loss: 1.0622 - val_accuracy: 0.5915\n",
      "Epoch 21/100\n",
      "897/897 [==============================] - 356s 397ms/step - loss: 1.1455 - accuracy: 0.5642 - val_loss: 1.0568 - val_accuracy: 0.5968\n",
      "Epoch 22/100\n",
      "897/897 [==============================] - 452s 504ms/step - loss: 1.1358 - accuracy: 0.5656 - val_loss: 1.0700 - val_accuracy: 0.5986\n",
      "Epoch 23/100\n",
      "897/897 [==============================] - 559s 623ms/step - loss: 1.1350 - accuracy: 0.5651 - val_loss: 1.0560 - val_accuracy: 0.6006\n",
      "Epoch 24/100\n",
      "897/897 [==============================] - 526s 586ms/step - loss: 1.1275 - accuracy: 0.5704 - val_loss: 1.0841 - val_accuracy: 0.5889\n",
      "Epoch 25/100\n",
      "897/897 [==============================] - 309s 344ms/step - loss: 1.1296 - accuracy: 0.5710 - val_loss: 1.0434 - val_accuracy: 0.6066\n",
      "Epoch 26/100\n",
      "897/897 [==============================] - 168s 187ms/step - loss: 1.1198 - accuracy: 0.5751 - val_loss: 1.0660 - val_accuracy: 0.5953\n",
      "Epoch 27/100\n",
      "897/897 [==============================] - 168s 188ms/step - loss: 1.1164 - accuracy: 0.5777 - val_loss: 1.0585 - val_accuracy: 0.5978\n",
      "Epoch 28/100\n",
      "897/897 [==============================] - 165s 184ms/step - loss: 1.1139 - accuracy: 0.5761 - val_loss: 1.1352 - val_accuracy: 0.5767\n",
      "Epoch 29/100\n",
      "897/897 [==============================] - 164s 183ms/step - loss: 1.1050 - accuracy: 0.5825 - val_loss: 1.0492 - val_accuracy: 0.6044\n",
      "Epoch 30/100\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.1050 - accuracy: 0.5815 - val_loss: 1.0432 - val_accuracy: 0.6055\n",
      "Epoch 31/100\n",
      "897/897 [==============================] - 171s 191ms/step - loss: 1.0988 - accuracy: 0.5823 - val_loss: 1.0511 - val_accuracy: 0.6070\n",
      "Epoch 32/100\n",
      "897/897 [==============================] - 164s 183ms/step - loss: 1.1029 - accuracy: 0.5837 - val_loss: 1.0671 - val_accuracy: 0.6018\n",
      "Epoch 33/100\n",
      "897/897 [==============================] - 175s 195ms/step - loss: 1.0911 - accuracy: 0.5881 - val_loss: 1.0455 - val_accuracy: 0.6076\n",
      "Epoch 34/100\n",
      "897/897 [==============================] - 177s 198ms/step - loss: 1.0913 - accuracy: 0.5839 - val_loss: 1.1090 - val_accuracy: 0.5774\n",
      "Epoch 35/100\n",
      "897/897 [==============================] - 190s 211ms/step - loss: 1.0884 - accuracy: 0.5909 - val_loss: 1.0522 - val_accuracy: 0.6085\n",
      "Epoch 36/100\n",
      "897/897 [==============================] - 177s 197ms/step - loss: 1.0908 - accuracy: 0.5870 - val_loss: 1.0323 - val_accuracy: 0.6130\n",
      "Epoch 37/100\n",
      "897/897 [==============================] - 163s 181ms/step - loss: 1.0823 - accuracy: 0.5907 - val_loss: 1.0616 - val_accuracy: 0.6007\n",
      "Epoch 38/100\n",
      "897/897 [==============================] - 191s 213ms/step - loss: 1.0796 - accuracy: 0.5898 - val_loss: 1.0636 - val_accuracy: 0.5995\n",
      "Epoch 39/100\n",
      "897/897 [==============================] - 160s 179ms/step - loss: 1.0804 - accuracy: 0.5922 - val_loss: 1.0431 - val_accuracy: 0.6106\n",
      "Epoch 40/100\n",
      "897/897 [==============================] - 173s 193ms/step - loss: 1.0806 - accuracy: 0.5909 - val_loss: 1.0251 - val_accuracy: 0.6200\n",
      "Epoch 41/100\n",
      "897/897 [==============================] - 188s 210ms/step - loss: 1.0708 - accuracy: 0.5952 - val_loss: 1.0344 - val_accuracy: 0.6127\n",
      "Epoch 42/100\n",
      "897/897 [==============================] - 184s 206ms/step - loss: 1.0720 - accuracy: 0.5941 - val_loss: 1.0468 - val_accuracy: 0.6097\n",
      "Epoch 43/100\n",
      "897/897 [==============================] - 187s 209ms/step - loss: 1.0679 - accuracy: 0.5955 - val_loss: 1.0459 - val_accuracy: 0.6137\n",
      "Epoch 44/100\n",
      "897/897 [==============================] - 443s 495ms/step - loss: 1.0625 - accuracy: 0.5974 - val_loss: 1.0532 - val_accuracy: 0.6045\n",
      "Epoch 45/100\n",
      "897/897 [==============================] - 521s 581ms/step - loss: 1.0650 - accuracy: 0.5980 - val_loss: 1.0461 - val_accuracy: 0.6059\n",
      "Epoch 46/100\n",
      "897/897 [==============================] - 288s 321ms/step - loss: 1.0587 - accuracy: 0.5987 - val_loss: 1.0333 - val_accuracy: 0.6088\n",
      "Epoch 47/100\n",
      "897/897 [==============================] - 389s 434ms/step - loss: 1.0587 - accuracy: 0.5981 - val_loss: 1.0225 - val_accuracy: 0.6200\n",
      "Epoch 48/100\n",
      "897/897 [==============================] - 215s 239ms/step - loss: 1.0602 - accuracy: 0.5988 - val_loss: 1.0646 - val_accuracy: 0.6035\n",
      "Epoch 49/100\n",
      "897/897 [==============================] - 158s 176ms/step - loss: 1.0556 - accuracy: 0.6014 - val_loss: 1.0214 - val_accuracy: 0.6169\n",
      "Epoch 50/100\n",
      "897/897 [==============================] - 172s 191ms/step - loss: 1.0615 - accuracy: 0.6002 - val_loss: 1.0337 - val_accuracy: 0.6157\n",
      "Epoch 51/100\n",
      "897/897 [==============================] - 247s 275ms/step - loss: 1.0474 - accuracy: 0.6076 - val_loss: 1.0314 - val_accuracy: 0.6134\n",
      "Epoch 52/100\n",
      "897/897 [==============================] - 153s 170ms/step - loss: 1.0509 - accuracy: 0.6038 - val_loss: 1.0392 - val_accuracy: 0.6150\n",
      "Epoch 53/100\n",
      "897/897 [==============================] - 158s 176ms/step - loss: 1.0386 - accuracy: 0.6093 - val_loss: 1.0280 - val_accuracy: 0.6106\n",
      "Epoch 54/100\n",
      "897/897 [==============================] - 198s 220ms/step - loss: 1.0484 - accuracy: 0.6068 - val_loss: 1.0516 - val_accuracy: 0.6085\n",
      "Epoch 55/100\n",
      "897/897 [==============================] - 152s 169ms/step - loss: 1.0405 - accuracy: 0.6095 - val_loss: 1.0357 - val_accuracy: 0.6126\n",
      "Epoch 56/100\n",
      "897/897 [==============================] - 161s 180ms/step - loss: 1.0402 - accuracy: 0.6090 - val_loss: 1.0475 - val_accuracy: 0.6108\n",
      "Epoch 57/100\n",
      "897/897 [==============================] - 151s 168ms/step - loss: 1.0375 - accuracy: 0.6066 - val_loss: 1.0376 - val_accuracy: 0.6159\n",
      "Epoch 58/100\n",
      "897/897 [==============================] - 151s 168ms/step - loss: 1.0341 - accuracy: 0.6097 - val_loss: 1.0352 - val_accuracy: 0.6127\n",
      "Epoch 59/100\n",
      "897/897 [==============================] - 171s 191ms/step - loss: 1.0342 - accuracy: 0.6098 - val_loss: 1.0251 - val_accuracy: 0.6164\n",
      "Epoch 60/100\n",
      "897/897 [==============================] - 165s 184ms/step - loss: 1.0355 - accuracy: 0.6093 - val_loss: 1.0097 - val_accuracy: 0.6257\n",
      "Epoch 61/100\n",
      "897/897 [==============================] - 152s 169ms/step - loss: 1.0301 - accuracy: 0.6129 - val_loss: 1.0281 - val_accuracy: 0.6217\n",
      "Epoch 62/100\n",
      "897/897 [==============================] - 151s 169ms/step - loss: 1.0364 - accuracy: 0.6104 - val_loss: 1.0310 - val_accuracy: 0.6141\n",
      "Epoch 63/100\n",
      "897/897 [==============================] - 165s 184ms/step - loss: 1.0290 - accuracy: 0.6115 - val_loss: 1.0143 - val_accuracy: 0.6214\n",
      "Epoch 64/100\n",
      "897/897 [==============================] - 150s 167ms/step - loss: 1.0243 - accuracy: 0.6132 - val_loss: 1.0322 - val_accuracy: 0.6222\n",
      "Epoch 65/100\n",
      "897/897 [==============================] - 159s 178ms/step - loss: 1.0222 - accuracy: 0.6139 - val_loss: 1.0188 - val_accuracy: 0.6221\n",
      "Epoch 66/100\n",
      "897/897 [==============================] - 175s 195ms/step - loss: 1.0290 - accuracy: 0.6121 - val_loss: 1.0443 - val_accuracy: 0.6148\n",
      "Epoch 67/100\n",
      "897/897 [==============================] - 162s 181ms/step - loss: 1.0260 - accuracy: 0.6127 - val_loss: 1.0261 - val_accuracy: 0.6215\n",
      "Epoch 68/100\n",
      "897/897 [==============================] - 167s 186ms/step - loss: 1.0191 - accuracy: 0.6146 - val_loss: 1.0336 - val_accuracy: 0.6126\n",
      "Epoch 69/100\n",
      "897/897 [==============================] - 159s 177ms/step - loss: 1.0167 - accuracy: 0.6164 - val_loss: 1.0527 - val_accuracy: 0.6126\n",
      "Epoch 70/100\n",
      "897/897 [==============================] - 159s 178ms/step - loss: 1.0206 - accuracy: 0.6162 - val_loss: 1.0345 - val_accuracy: 0.6235\n",
      "Epoch 71/100\n",
      "897/897 [==============================] - 163s 181ms/step - loss: 1.0157 - accuracy: 0.6166 - val_loss: 1.0256 - val_accuracy: 0.6277\n",
      "Epoch 72/100\n",
      "897/897 [==============================] - 177s 198ms/step - loss: 1.0165 - accuracy: 0.6197 - val_loss: 1.0475 - val_accuracy: 0.6147\n",
      "Epoch 73/100\n",
      "897/897 [==============================] - 180s 200ms/step - loss: 1.0162 - accuracy: 0.6166 - val_loss: 1.0504 - val_accuracy: 0.6250\n",
      "Epoch 74/100\n",
      "897/897 [==============================] - 174s 194ms/step - loss: 1.0151 - accuracy: 0.6176 - val_loss: 1.0363 - val_accuracy: 0.6247\n",
      "Epoch 75/100\n",
      "897/897 [==============================] - 173s 193ms/step - loss: 1.0152 - accuracy: 0.6183 - val_loss: 1.0248 - val_accuracy: 0.6223\n",
      "Epoch 76/100\n",
      "897/897 [==============================] - 172s 192ms/step - loss: 1.0106 - accuracy: 0.6205 - val_loss: 1.0278 - val_accuracy: 0.6244\n",
      "Epoch 77/100\n",
      "897/897 [==============================] - 172s 192ms/step - loss: 1.0154 - accuracy: 0.6142 - val_loss: 1.0238 - val_accuracy: 0.6179\n",
      "Epoch 78/100\n",
      "897/897 [==============================] - 175s 195ms/step - loss: 1.0054 - accuracy: 0.6236 - val_loss: 1.0208 - val_accuracy: 0.6279\n",
      "Epoch 79/100\n",
      "897/897 [==============================] - 172s 191ms/step - loss: 1.0052 - accuracy: 0.6225 - val_loss: 1.0302 - val_accuracy: 0.6275\n",
      "Epoch 80/100\n",
      "897/897 [==============================] - 170s 190ms/step - loss: 1.0002 - accuracy: 0.6207 - val_loss: 1.0315 - val_accuracy: 0.6235\n",
      "Epoch 81/100\n",
      "897/897 [==============================] - 170s 189ms/step - loss: 1.0006 - accuracy: 0.6239 - val_loss: 1.0085 - val_accuracy: 0.6316\n",
      "Epoch 82/100\n",
      "897/897 [==============================] - 168s 187ms/step - loss: 0.9988 - accuracy: 0.6258 - val_loss: 1.0202 - val_accuracy: 0.6243\n",
      "Epoch 83/100\n",
      "897/897 [==============================] - 170s 189ms/step - loss: 1.0063 - accuracy: 0.6215 - val_loss: 1.0403 - val_accuracy: 0.6169\n",
      "Epoch 84/100\n",
      "897/897 [==============================] - 173s 192ms/step - loss: 1.0014 - accuracy: 0.6244 - val_loss: 1.0199 - val_accuracy: 0.6225\n",
      "Epoch 85/100\n",
      "897/897 [==============================] - 169s 188ms/step - loss: 0.9996 - accuracy: 0.6208 - val_loss: 1.0391 - val_accuracy: 0.6126\n",
      "Epoch 86/100\n",
      "897/897 [==============================] - 169s 188ms/step - loss: 0.9963 - accuracy: 0.6236 - val_loss: 1.0203 - val_accuracy: 0.6232\n",
      "Epoch 87/100\n",
      "897/897 [==============================] - 171s 190ms/step - loss: 1.0053 - accuracy: 0.6207 - val_loss: 1.0126 - val_accuracy: 0.6232\n",
      "Epoch 88/100\n",
      "897/897 [==============================] - 172s 192ms/step - loss: 0.9904 - accuracy: 0.6270 - val_loss: 1.0214 - val_accuracy: 0.6249\n",
      "Epoch 89/100\n",
      "897/897 [==============================] - 173s 193ms/step - loss: 0.9903 - accuracy: 0.6250 - val_loss: 1.0361 - val_accuracy: 0.6264\n",
      "Epoch 90/100\n",
      "897/897 [==============================] - 170s 189ms/step - loss: 0.9894 - accuracy: 0.6304 - val_loss: 1.0387 - val_accuracy: 0.6176\n",
      "Epoch 91/100\n",
      "897/897 [==============================] - 170s 189ms/step - loss: 0.9924 - accuracy: 0.6251 - val_loss: 1.0312 - val_accuracy: 0.6285\n",
      "Epoch 92/100\n",
      "897/897 [==============================] - 172s 192ms/step - loss: 0.9927 - accuracy: 0.6265 - val_loss: 1.0387 - val_accuracy: 0.6212\n",
      "Epoch 93/100\n",
      "897/897 [==============================] - 174s 194ms/step - loss: 0.9931 - accuracy: 0.6261 - val_loss: 1.0204 - val_accuracy: 0.6292\n",
      "Epoch 94/100\n",
      "897/897 [==============================] - 172s 191ms/step - loss: 0.9903 - accuracy: 0.6229 - val_loss: 1.0417 - val_accuracy: 0.6232\n",
      "Epoch 95/100\n",
      "897/897 [==============================] - 178s 199ms/step - loss: 0.9853 - accuracy: 0.6274 - val_loss: 1.0343 - val_accuracy: 0.6250\n",
      "Epoch 96/100\n",
      "897/897 [==============================] - 177s 197ms/step - loss: 0.9888 - accuracy: 0.6254 - val_loss: 1.0362 - val_accuracy: 0.6182\n",
      "Epoch 97/100\n",
      "897/897 [==============================] - 172s 191ms/step - loss: 0.9865 - accuracy: 0.6331 - val_loss: 1.0305 - val_accuracy: 0.6243\n",
      "Epoch 98/100\n",
      "897/897 [==============================] - 173s 192ms/step - loss: 0.9886 - accuracy: 0.6238 - val_loss: 1.0170 - val_accuracy: 0.6299\n",
      "Epoch 99/100\n",
      "897/897 [==============================] - 173s 193ms/step - loss: 0.9810 - accuracy: 0.6294 - val_loss: 1.0207 - val_accuracy: 0.6250\n",
      "Epoch 100/100\n",
      "897/897 [==============================] - 171s 190ms/step - loss: 0.9823 - accuracy: 0.6311 - val_loss: 1.0425 - val_accuracy: 0.6138\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "history=model.fit(train_generator,\n",
    "                steps_per_epoch=num_train_imgs//32,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=num_test_imgs//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ricardo Caceres\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import save_model\n",
    "\n",
    "# Guradamos el modelo para poder usarlo despues\n",
    "model.save('recofnition_100epochs.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
